{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# RAG Chatbot with PDF Support for Google Colab\n",
        "# Run each cell in sequence\n",
        "\n",
        "# Cell 1: Install required packages (including PDF support)\n",
        "!pip install sentence-transformers faiss-cpu groq PyPDF2 python-docx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hZAlV29ABCAD",
        "outputId": "c0ce9a5f-bb34-47f0-b487-50a8885d7829"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.0)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting groq\n",
            "  Downloading groq-0.31.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting python-docx\n",
            "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.55.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.34.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.8)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groq-0.31.0-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.4/131.4 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx, PyPDF2, faiss-cpu, groq\n",
            "Successfully installed PyPDF2-3.0.1 faiss-cpu-1.12.0 groq-0.31.0 python-docx-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Import libraries\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import pickle\n",
        "import os\n",
        "from groq import Groq\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import PyPDF2\n",
        "import docx\n",
        "import io\n",
        "import re\n",
        "\n",
        "# TODO: Enter your Groq API key here\n",
        "GROQ_API_KEY = \"\"  # Get free API key from https://console.groq.com/\n",
        "\n",
        "# Initialize models\n",
        "print(\"Loading models...\")\n",
        "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "groq_client = Groq(api_key=GROQ_API_KEY) if GROQ_API_KEY else None\n",
        "print(\"✅ Models loaded!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "IIxjP7bLBLRd",
        "outputId": "e2784c40-0eaa-4cd8-bf03-aaf6c066688b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading models...\n",
            "✅ Models loaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cell 3: Enhanced Vector Store with Document Processing\n",
        "class DocumentVectorStore:\n",
        "    def __init__(self):\n",
        "        self.texts = []\n",
        "        self.embeddings = []\n",
        "        self.metadata = []  # Store document info\n",
        "\n",
        "    def add_texts(self, texts, source=\"manual\"):\n",
        "        \"\"\"Add texts to the store\"\"\"\n",
        "        if isinstance(texts, str):\n",
        "            texts = [texts]\n",
        "\n",
        "        for text in texts:\n",
        "            # Split long texts into chunks\n",
        "            chunks = self._split_text(text)\n",
        "            for chunk in chunks:\n",
        "                if len(chunk.strip()) > 10:  # Only add meaningful chunks\n",
        "                    embedding = sentence_model.encode([chunk])[0]\n",
        "                    self.texts.append(chunk)\n",
        "                    self.embeddings.append(embedding)\n",
        "                    self.metadata.append({\"source\": source, \"length\": len(chunk)})\n",
        "\n",
        "        print(f\"✅ Added {len([t for t in texts if len(t.strip()) > 10])} documents from {source}\")\n",
        "        print(f\"📊 Total chunks in knowledge base: {len(self.texts)}\")\n",
        "\n",
        "    def _split_text(self, text, chunk_size=500):\n",
        "        \"\"\"Split text into smaller chunks\"\"\"\n",
        "        # Split by sentences first\n",
        "        sentences = re.split(r'[.!?]+', text)\n",
        "        chunks = []\n",
        "        current_chunk = \"\"\n",
        "\n",
        "        for sentence in sentences:\n",
        "            sentence = sentence.strip()\n",
        "            if len(current_chunk) + len(sentence) < chunk_size:\n",
        "                current_chunk += sentence + \". \"\n",
        "            else:\n",
        "                if current_chunk:\n",
        "                    chunks.append(current_chunk.strip())\n",
        "                current_chunk = sentence + \". \"\n",
        "\n",
        "        if current_chunk:\n",
        "            chunks.append(current_chunk.strip())\n",
        "\n",
        "        return chunks if chunks else [text]\n",
        "\n",
        "    def search(self, query, k=3):\n",
        "        \"\"\"Search for similar texts\"\"\"\n",
        "        if not self.embeddings:\n",
        "            return []\n",
        "\n",
        "        query_embedding = sentence_model.encode([query])[0]\n",
        "\n",
        "        # Calculate cosine similarities\n",
        "        similarities = []\n",
        "        for i, doc_embedding in enumerate(self.embeddings):\n",
        "            similarity = np.dot(query_embedding, doc_embedding) / (\n",
        "                np.linalg.norm(query_embedding) * np.linalg.norm(doc_embedding)\n",
        "            )\n",
        "            similarities.append((similarity, i))\n",
        "\n",
        "        # Get top k results\n",
        "        similarities.sort(reverse=True)\n",
        "        results = []\n",
        "        for sim, idx in similarities[:k]:\n",
        "            results.append({\n",
        "                'text': self.texts[idx],\n",
        "                'similarity': sim,\n",
        "                'metadata': self.metadata[idx]\n",
        "            })\n",
        "\n",
        "        return results"
      ],
      "metadata": {
        "id": "nwEDfZL8BaML"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cell 4: Document Processing Functions\n",
        "def extract_text_from_pdf(pdf_content):\n",
        "    \"\"\"Extract text from PDF bytes\"\"\"\n",
        "    try:\n",
        "        pdf_reader = PyPDF2.PdfReader(io.BytesIO(pdf_content))\n",
        "        text = \"\"\n",
        "        for page in pdf_reader.pages:\n",
        "            text += page.extract_text() + \"\\n\"\n",
        "        return text.strip()\n",
        "    except Exception as e:\n",
        "        return f\"Error reading PDF: {str(e)}\"\n",
        "\n",
        "def extract_text_from_docx(docx_content):\n",
        "    \"\"\"Extract text from DOCX bytes\"\"\"\n",
        "    try:\n",
        "        doc = docx.Document(io.BytesIO(docx_content))\n",
        "        text = \"\"\n",
        "        for paragraph in doc.paragraphs:\n",
        "            text += paragraph.text + \"\\n\"\n",
        "        return text.strip()\n",
        "    except Exception as e:\n",
        "        return f\"Error reading DOCX: {str(e)}\"\n",
        "\n",
        "def process_uploaded_file(file_content, filename):\n",
        "    \"\"\"Process uploaded file based on extension\"\"\"\n",
        "    file_ext = filename.lower().split('.')[-1]\n",
        "\n",
        "    if file_ext == 'pdf':\n",
        "        return extract_text_from_pdf(file_content)\n",
        "    elif file_ext in ['docx', 'doc']:\n",
        "        return extract_text_from_docx(file_content)\n",
        "    elif file_ext == 'txt':\n",
        "        return file_content.decode('utf-8')\n",
        "    else:\n",
        "        return f\"Unsupported file type: {file_ext}\"\n"
      ],
      "metadata": {
        "id": "JxtMMPzdB0JQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Cell 5: Initialize Knowledge Base\n",
        "vector_store = DocumentVectorStore()\n",
        "\n",
        "# Sample knowledge base\n",
        "sample_knowledge = [\n",
        "    \"Python is a high-level programming language known for its simplicity and readability. It was created by Guido van Rossum and first released in 1991.\",\n",
        "    \"Machine learning is a subset of artificial intelligence that enables computers to learn from data without explicit programming for every task.\",\n",
        "    \"Streamlit is an open-source Python library for creating web applications for data science and machine learning projects.\",\n",
        "    \"RAG (Retrieval Augmented Generation) combines information retrieval with text generation for better AI responses.\",\n",
        "    \"Vector databases store high-dimensional vectors and enable similarity search for AI applications like semantic search.\",\n",
        "    \"Natural Language Processing helps computers understand and work with human language through various algorithms.\",\n",
        "    \"Deep learning uses neural networks with multiple layers to learn complex patterns from large amounts of data.\",\n",
        "    \"APIs allow different software applications to communicate and share data with each other seamlessly.\",\n",
        "    \"Data science combines statistics, programming, and domain knowledge to extract insights from structured and unstructured data.\",\n",
        "    \"Cloud computing provides on-demand access to computing resources over the internet without local infrastructure.\"\n",
        "]\n",
        "\n",
        "vector_store.add_texts(sample_knowledge, source=\"initial_knowledge\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "cjjy3rIVB70S",
        "outputId": "4f3ebc61-d767-4aa7-b1d7-5623fd2b6e7f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Added 10 documents from initial_knowledge\n",
            "📊 Total chunks in knowledge base: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# Cell 6: Enhanced RAG Functions\n",
        "def search_knowledge_base(query):\n",
        "    \"\"\"Search the knowledge base for relevant information\"\"\"\n",
        "    results = vector_store.search(query, k=3)\n",
        "    if results:\n",
        "        context_parts = []\n",
        "        for result in results:\n",
        "            source = result['metadata']['source']\n",
        "            context_parts.append(f\"[From {source}] {result['text']}\")\n",
        "        return \"\\n\\n\".join(context_parts)\n",
        "    return \"No relevant information found.\"\n",
        "\n",
        "def generate_response(query, context):\n",
        "    \"\"\"Generate response using Groq API\"\"\"\n",
        "    if not groq_client:\n",
        "        return \"❌ Please add your Groq API key!\"\n",
        "\n",
        "    prompt = f\"\"\"You are a helpful assistant. Answer the user's question based on the provided context. If the answer is not in the context, say \"I don't have enough information to answer that accurately.\"\n",
        "\n",
        "Context from knowledge base:\n",
        "{context}\n",
        "\n",
        "Question: {query}\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = groq_client.chat.completions.create(\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            model=\"llama3-8b-8192\",  # Updated working model\n",
        "            temperature=0.7,\n",
        "            max_tokens=500\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "def chat_with_rag(query):\n",
        "    \"\"\"Main RAG chat function\"\"\"\n",
        "    print(f\"🔍 Searching knowledge base for: {query}\")\n",
        "\n",
        "    # Search for relevant context\n",
        "    context = search_knowledge_base(query)\n",
        "    print(f\"📚 Found relevant information from knowledge base...\")\n",
        "\n",
        "    # Generate response\n",
        "    print(\"🤖 Generating response...\")\n",
        "    response = generate_response(query, context)\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "6_LeowROCRFG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cell 7: Document Addition Functions\n",
        "def add_text(text, source_name=\"manual_input\"):\n",
        "    \"\"\"Add plain text to knowledge base\"\"\"\n",
        "    vector_store.add_texts(text, source=source_name)\n",
        "\n",
        "def add_pdf_from_upload():\n",
        "    \"\"\"Instructions for adding PDF in Colab\"\"\"\n",
        "    print(\"📄 To add a PDF file:\")\n",
        "    print(\"1. Upload your PDF to Colab using the file browser (left sidebar)\")\n",
        "    print(\"2. Use: add_pdf_file('your_file.pdf')\")\n",
        "    print(\"3. Or drag & drop and copy the file path\")\n",
        "\n",
        "def add_pdf_file(file_path):\n",
        "    \"\"\"Add PDF file to knowledge base\"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'rb') as file:\n",
        "            content = file.read()\n",
        "\n",
        "        text = extract_text_from_pdf(content)\n",
        "        if \"Error\" not in text:\n",
        "            vector_store.add_texts(text, source=f\"PDF: {file_path}\")\n",
        "            return f\"✅ Successfully added PDF: {file_path}\"\n",
        "        else:\n",
        "            return text\n",
        "    except Exception as e:\n",
        "        return f\"❌ Error reading file: {str(e)}\"\n",
        "\n",
        "def add_text_file(file_path):\n",
        "    \"\"\"Add text file to knowledge base\"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            content = file.read()\n",
        "\n",
        "        vector_store.add_texts(content, source=f\"TXT: {file_path}\")\n",
        "        return f\"✅ Successfully added text file: {file_path}\"\n",
        "    except Exception as e:\n",
        "        return f\"❌ Error reading file: {str(e)}\"\n"
      ],
      "metadata": {
        "id": "t3Pi7-qjCSZT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Cell 8: Interactive Chat Function\n",
        "def start_chat():\n",
        "    \"\"\"Start interactive chat session\"\"\"\n",
        "    if not GROQ_API_KEY:\n",
        "        print(\"❌ Please add your Groq API key first!\")\n",
        "        return\n",
        "\n",
        "    print(\"💬 RAG Chat started! (type 'quit' to exit)\")\n",
        "    print(\"📚 Ask questions about the knowledge base or upload documents first\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    while True:\n",
        "        query = input(\"\\n🧑 You: \").strip()\n",
        "\n",
        "        if query.lower() in ['quit', 'exit', 'bye']:\n",
        "            print(\"👋 Goodbye!\")\n",
        "            break\n",
        "\n",
        "        if not query:\n",
        "            continue\n",
        "\n",
        "        print(\"🤖 Bot: \", end=\"\")\n",
        "        response = chat_with_rag(query)\n",
        "        print(response)\n",
        "        print(\"-\" * 50)\n"
      ],
      "metadata": {
        "id": "PpOYDXpRCbsg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "tO866PONANYQ",
        "outputId": "450bc4f5-228f-494c-b5c6-1416ee49fbec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Enhanced RAG Chatbot with PDF Support Ready!\n",
            "============================================================\n",
            "✅ API key loaded!\n",
            "\n",
            "📋 HOW TO ADD DOCUMENTS:\n",
            "------------------------------\n",
            "1. TEXT: add_text('Your text here', 'source_name')\n",
            "2. PDF:  add_pdf_file('path/to/your/file.pdf')\n",
            "3. TXT:  add_text_file('path/to/your/file.txt')\n",
            "\n",
            "💡 EXAMPLES:\n",
            "---------------\n",
            "# Add custom text:\n",
            "add_text('Artificial intelligence is transforming healthcare.', 'healthcare_doc')\n",
            "\n",
            "# Add PDF (after uploading to Colab):\n",
            "add_pdf_file('/content/my_document.pdf')\n",
            "\n",
            "🤔 TRY ASKING:\n",
            "- What is Python?\n",
            "- Explain machine learning\n",
            "- Tell me about [your uploaded document topic]\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Cell 9: Usage Examples and Instructions\n",
        "print(\"🚀 Enhanced RAG Chatbot with PDF Support Ready!\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if not GROQ_API_KEY:\n",
        "    print(\"❌ Please add your Groq API key in GROQ_API_KEY variable!\")\n",
        "else:\n",
        "    print(\"✅ API key loaded!\")\n",
        "\n",
        "print(\"\\n📋 HOW TO ADD DOCUMENTS:\")\n",
        "print(\"-\" * 30)\n",
        "print(\"1. TEXT: add_text('Your text here', 'source_name')\")\n",
        "print(\"2. PDF:  add_pdf_file('path/to/your/file.pdf')\")\n",
        "print(\"3. TXT:  add_text_file('path/to/your/file.txt')\")\n",
        "\n",
        "print(\"\\n💡 EXAMPLES:\")\n",
        "print(\"-\" * 15)\n",
        "print(\"# Add custom text:\")\n",
        "print(\"add_text('Artificial intelligence is transforming healthcare.', 'healthcare_doc')\")\n",
        "print(\"\\n# Add PDF (after uploading to Colab):\")\n",
        "print(\"add_pdf_file('/content/my_document.pdf')\")\n",
        "\n",
        "print(\"\\n🤔 TRY ASKING:\")\n",
        "print(\"- What is Python?\")\n",
        "print(\"- Explain machine learning\")\n",
        "print(\"- Tell me about [your uploaded document topic]\")\n",
        "print(\"\\n\" + \"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cell 10: Quick Test\n",
        "print(\"🧪 Quick Test:\")\n",
        "response = chat_with_rag(\"What is Python?\")\n",
        "print(f\"Response: {response}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "X2CljiE9Ce2g",
        "outputId": "b62d77ad-f7fe-43fa-f058-b372709ae944"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧪 Quick Test:\n",
            "🔍 Searching knowledge base for: What is Python?\n",
            "📚 Found relevant information from knowledge base...\n",
            "🤖 Generating response...\n",
            "Response: According to the context, Python is a high-level programming language known for its simplicity and readability, created by Guido van Rossum and first released in 1991.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#adding the pdf that we want, can ask questions if loaded properly\n",
        "add_pdf_file(\"/content/Placement_Manual.pdf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "Wy4M7wC6Cj8f",
        "outputId": "cec47ea6-8467-4cda-ada8-34ddf9fbabdd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Added 1 documents from PDF: /content/Placement_Manual.pdf\n",
            "📊 Total chunks in knowledge base: 28\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'✅ Successfully added PDF: /content/Placement_Manual.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 11: Start chatting (run this to begin)\n",
        "\n",
        "start_chat()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "cB8JCBqsChdZ",
        "outputId": "3fcd6ea9-a16c-4197-b2a2-654a892c430c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💬 RAG Chat started! (type 'quit' to exit)\n",
            "📚 Ask questions about the knowledge base or upload documents first\n",
            "--------------------------------------------------\n",
            "\n",
            "🧑 You: what the pdf says about linear regression?\n",
            "🤖 Bot: 🔍 Searching knowledge base for: what the pdf says about linear regression?\n",
            "📚 Found relevant information from knowledge base...\n",
            "🤖 Generating response...\n",
            "According to the PDF, it is mentioned that one project is required on Linear Regression, where you need to \"do every statistical thing you know about linear regression\".\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2040475346.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Cell 11: Start chatting (run this to begin)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mstart_chat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3329758126.py\u001b[0m in \u001b[0;36mstart_chat\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n🧑 You: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'quit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bye'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A0pueScoDLCj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}